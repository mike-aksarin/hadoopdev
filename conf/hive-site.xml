<configuration>
    <property>
        <name>hive.metastore.uris</name>
        <value><!-- No URIs â€” local mode --></value>
    </property>
    <property>
        <name>hive.metastore.warehouse.dir</name>
        <value>hdfs://localhost:9000/user/hive/warehouse</value>
    </property>
    <property>
        <name>javax.jdo.option.ConnectionURL</name>
        <value>jdbc:postgresql://localhost:5432/hive_metastore</value>
    </property>
    <property>
        <name>javax.jdo.option.ConnectionDriverName</name>
        <value>org.postgresql.Driver</value>
    </property>
    <property>
        <name>datanucleus.autoCreateSchema</name>
        <value>false</value>
    </property>
    <property>
        <name>javax.jdo.option.ConnectionUserName</name>
        <value>hive</value>
    </property>
    <property>
        <name>javax.jdo.option.ConnectionPassword</name>
        <value>hive</value>
    </property>
    <property>
        <name>hive.execution.engine</name>
        <value>yarn</value>
    </property>
<!--    <property>-->
<!--        <name>hive.execution.engine</name>-->
<!--        <value>spark</value>-->
<!--    </property>-->
<!--    <property>-->
<!--        <name>spark.home</name>-->
<!--        <value>/usr/local/spark</value>-->
<!--    </property>-->
<!--    <property>-->
<!--        <name>spark.master</name>-->
<!--        <value>local[*]</value>-->
<!--    </property>-->
<!--    <property>-->
<!--        <name>spark.eventLog.enabled</name>-->
<!--        <value>true</value>-->
<!--    </property>-->
<!--    <property>-->
<!--        <name>spark.eventLog.dir</name>-->
<!--        <value>/work/hive-spark-log</value>-->
<!--    </property>-->
<!--    <property>-->
<!--        <name>spark.executor.memory</name>-->
<!--        <value>1g</value>-->
<!--    </property>-->
    <!-- Set the YARN Container memory and maximum to be greater than Spark Executor Memory + Overhead -->
<!--    <property>-->
        <!-- RAM per container -->
<!--        <name>yarn.scheduler.minimum-allocation-mb</name>-->
<!--        <value>2g</value>-->
<!--    </property>-->
<!--    <property>-->
        <!-- Max RAM per container -->
<!--        <name>yarn.scheduler.maximum-allocation-mb</name>-->
<!--        <value>8g</value>-->
<!--    </property>-->
<!--    <property>-->
<!--        <name>yarn.nodemanager.resource.memory-mb</name>-->
<!--        <value>40g</value>-->
<!--    </property>-->
<!--    <property>-->
<!--        <name>spark.serializer</name>-->
<!--        <value>org.apache.spark.serializer.KryoSerializer</value>-->
<!--    </property>-->
<!--    <property>-->
<!--        <name>spark.yarn.jars</name>-->
<!--        <value>hdfs://localhost:9000/spark-jars/*</value>-->
<!--    </property>-->
    <!--    <property>-->
    <!--        <name>hive.server2.thrift.bind.host</name>-->
    <!--        <value>localhost</value>-->
    <!--        <description>Bind host on which to run the HiveServer2 Thrift service.</description>-->
    <!--    </property>-->
    <!--    <property>-->
    <!--        <name>hive.metastore.uris</name>-->
    <!--        <value>thrift://localhost:9083</value>-->
    <!--    </property>-->
</configuration>
